<!DOCTYPE html>
<html>

<head>
<% include templates/head %>
<link rel='stylesheet' href='stylesheets/case.css' type='text/css'>
</head>

<body class='case-study' id="dais-case">
	<div class='hero' id='dais'>
		<div class='intro row'>
			<div class='large-12 large-centered columns'>
				<div class="back"><a href="http://elainezhou.me"><img src="images/logoWhite.png" alt='Personal logo'></a></div>
				<div class="intro-text">
					<h1>Dais</h1>
					<h2>Live presentation aid and analytics.</h2>
					<h3>Google Glass, HTML/CSS/Javascript | 2014</h3>
				</div>
			</div>
		</div>
	</div>
	<div class='case-content row'>
		<div class='large-12 large-centered columns'>
			<section id='stats'>
				<div class="large-12 large-centered columns">
					<div class="row">
						<div class="large-7 medium-6 columns">
							<h4>Context</h4>
							<p>
							Coursework: 6 week project<br />
							Dream Team: Brian Lam, Harrison Wray, Adrian Rodriguez
							</p>
						</div>
						<div class="large-5 medium-6 columns">
							<h4>Roles</h4>
							<p>User Interviews, Interaction Design, Prototyping, Data Visualization</p>
						</div>
					</div>

				</div>
			</section>

			<section id='overview'>
				<div class="medium-8 medium-centered columns">
					<h1>Present Better</h1>

					<p>Why is public speaking so difficult? Many presentation aids neither teach nor reinforce good speaking techniques. Instead, they focus on peripherals: making presenter’s notes more accessible or slide changes easier. Dais focuses on two core issues: eye gaze and vocal variation. Dais aims to help novice oral presenters to receive real-time feedback and present aggregate trends of their performances.
					</p>
				</div>
				
				<div class='video-wrapper center'>
					<iframe width="560" height="315" src="https://www.youtube.com/embed/x7TjLtVKj3k" allowfullscreen></iframe>
				</div>
			</section>

			<section id='needfinding'>
				<div class="medium-8 medium-centered columns">
					<h1>Needfinding</h1>

					<p>We observed and talked with novice speakers and interviewed two professional oral communicator lecturers - <a href='https://www.linkedin.com/pub/matt-vassar/28/196/798'>Matt Vassar</a> and <a href='http://vpuewh-public.stanford.edu/viewprofile.jsp?sunetid=sohui&usetype=P&userid=PWR'>Sohui Lee</a>. Students in public speaking courses mentioned problems with current solutions: (1) video debugging is incredibly awkward and is too far removed from the act of public speaking, whereas (2) immediate feedback is overwhelming in that there's too cognitive load to focus on any one bit of advice.</p>

					<blockquote>There's too much "stuff" to improve on; I can't focus on any of it! <footer>- Oral Communication Student</footer></blockquote>

					<p>Thus, we learned that feedback is only helpful in small and immediate doses. We focused on two main pillars of good presentations: <em>balanced visual spread</em> and <em>consistent speaking volume</em>.
					</p>
				</div>

			</section>

			<section id='glass'>
				<div class="medium-8 medium-centered columns">
					<h1>Google Glass Prototyping</h1>

					<p>By taking initial reference points from the accelerometer and microphone, Dais monitors where the user is looking and their volume. It then provides immediate feedback on eye-contact spread and volume. For example, if a user spends a disproportionate large amount of time looking at audience members to his/her left, Dais displays a subtle suggestion to look elsewhere. If the user looks far out of the range of the audience, Dais assumes the user has turned their head away from the audience to read off their own slides telling the user to face forward. We prototyped some screens for immediate visual and aural feedback. 
					</p>
				</div>
				<figure class="large-12 columns">
					<img src='images/dais/directionalView.png' alt='Interface for a directional view (using arrows to indicate direction)'/>
					<img src='images/dais/spatialView.png' alt='Interface for a spatial view (using blocks to indicate space)'/>
					<figcaption>We prototyped two different types of feedback cues for Glass – directional (top) and spatial (bottom).</figcaption>
				</figure>
				<div class="medium-8 medium-centered columns">

					<p>We also prototyped some visualizations summarizing an entire presentation - heat map of head position to model visual spread and a line graph charting the progression of the speaker’s volume. However, it was immediately clear from user feedback that this information was too dense and unnecessary for Glass' intended use case.
					</p>
				</div>

				<figure class="large-12 columns">
					<!-- <img src='images/dais/glassAural.png' /> -->
					<img src='images/dais/glassVisual.png' alt='Speech analytics on Glass interface' />
					<figcaption>We tried displaying these analytics on Glass, but they were incomprehensible.</figcaption>
				</figure>

			</section>

			<section id='web'>
				<div class="medium-8 medium-centered columns">
					<h1>Web App Component</h1>
					<p>Taking these insights into account, we built a real-time app platform on which the presenter can view important metrics from any previously given presentationa. Since the goal of post-presentation evaluation is pinpointing and correcting errors made during the presentation, the analytics were designed with the intention of highlighting errors made. The heat map highlights the user's tendency to stare at any single point, and the volume line graph indicates the user's volume relative to a desired speaking level. The web app also aggregate all presentations over time in one dashboard.
					</p>
				</div>

				<figure class="large-12 columns">
					<img src='images/dais/webapp.png' alt='Displaying the aggregate analytics after a presentation'/>
					<figcaption>The web app displays aggregate analytics after the presentation has ended.</figcaption>
				</figure>

			</section>
		</div>
	</div>

<% include templates/footer %>
<% include templates/scripts %>

</body>
</html>